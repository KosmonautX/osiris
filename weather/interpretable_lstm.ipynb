{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ksatrayamaii/.virtualenvs/cds/lib/python3.9/site-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['plt']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMVFullLSTM(torch.jit.ScriptModule):\n",
    "    __constants__ = [\"n_units\", \"input_dim\"]\n",
    "    def __init__(self, input_dim, output_dim, n_units, init_std=0.02):\n",
    "        super().__init__()\n",
    "        self.U_j = nn.Parameter(torch.randn(input_dim, 1, n_units)*init_std)\n",
    "        self.W_j = nn.Parameter(torch.randn(input_dim, n_units, n_units)*init_std)\n",
    "        self.b_j = nn.Parameter(torch.randn(input_dim, n_units)*init_std)\n",
    "        self.W_i = nn.Linear(input_dim*(n_units+1), input_dim*n_units)\n",
    "        self.W_f = nn.Linear(input_dim*(n_units+1), input_dim*n_units)\n",
    "        self.W_o = nn.Linear(input_dim*(n_units+1), input_dim*n_units)\n",
    "        self.F_alpha_n = nn.Parameter(torch.randn(input_dim, n_units, 1)*init_std)\n",
    "        self.F_alpha_n_b = nn.Parameter(torch.randn(input_dim, 1)*init_std)\n",
    "        self.F_beta = nn.Linear(2*n_units, 1)\n",
    "        self.Phi = nn.Linear(2*n_units, output_dim)\n",
    "        self.n_units = n_units\n",
    "        self.input_dim = input_dim\n",
    "    @torch.jit.script_method\n",
    "    def forward(self, x):\n",
    "        h_tilda_t = torch.zeros(x.shape[0], self.input_dim, self.n_units).cuda()\n",
    "        c_t = torch.zeros(x.shape[0], self.input_dim*self.n_units).cuda()\n",
    "        outputs = torch.jit.annotate(List[Tensor], [])\n",
    "        for t in range(x.shape[1]):\n",
    "            # eq 1\n",
    "            j_tilda_t = torch.tanh(torch.einsum(\"bij,ijk->bik\", h_tilda_t, self.W_j) + \\\n",
    "                                   torch.einsum(\"bij,jik->bjk\", x[:,t,:].unsqueeze(1), self.U_j) + self.b_j)\n",
    "            inp =  torch.cat([x[:, t, :], h_tilda_t.view(h_tilda_t.shape[0], -1)], dim=1)\n",
    "            # eq 2\n",
    "            i_t = torch.sigmoid(self.W_i(inp))\n",
    "            f_t = torch.sigmoid(self.W_f(inp))\n",
    "            o_t = torch.sigmoid(self.W_o(inp))\n",
    "            # eq 3\n",
    "            c_t = c_t*f_t + i_t*j_tilda_t.view(j_tilda_t.shape[0], -1)\n",
    "            # eq 4\n",
    "            h_tilda_t = (o_t*torch.tanh(c_t)).view(h_tilda_t.shape[0], self.input_dim, self.n_units)\n",
    "            outputs += [h_tilda_t]\n",
    "        outputs = torch.stack(outputs)\n",
    "        outputs = outputs.permute(1, 0, 2, 3)\n",
    "        # eq 8\n",
    "        alphas = torch.tanh(torch.einsum(\"btij,ijk->btik\", outputs, self.F_alpha_n) +self.F_alpha_n_b)\n",
    "        alphas = torch.exp(alphas)\n",
    "        alphas = alphas/torch.sum(alphas, dim=1, keepdim=True)\n",
    "        g_n = torch.sum(alphas*outputs, dim=1)\n",
    "        hg = torch.cat([g_n, h_tilda_t], dim=2)\n",
    "        mu = self.Phi(hg)\n",
    "        betas = torch.tanh(self.F_beta(hg))\n",
    "        betas = torch.exp(betas)\n",
    "        betas = betas/torch.sum(betas, dim=1, keepdim=True)\n",
    "        mean = torch.sum(betas*mu, dim=1)\n",
    "        return mean, alphas, betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"./NEW-DATA-1.T15.txt\", sep=' ')\n",
    "data2 = pd.read_csv(\"./NEW-DATA-2.T15.txt\", sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '3:Temperature_Comedor_Sensor'\n",
    "cols = [\n",
    "    '3:Temperature_Comedor_Sensor',\n",
    " '4:Temperature_Habitacion_Sensor',\n",
    " '5:Weather_Temperature',\n",
    " '6:CO2_Comedor_Sensor',\n",
    " '7:CO2_Habitacion_Sensor',\n",
    " '8:Humedad_Comedor_Sensor',\n",
    " '9:Humedad_Habitacion_Sensor',\n",
    " '10:Lighting_Comedor_Sensor',\n",
    " '11:Lighting_Habitacion_Sensor',\n",
    " '12:Precipitacion',\n",
    " '13:Meteo_Exterior_Crepusculo',\n",
    " '14:Meteo_Exterior_Viento',\n",
    " '15:Meteo_Exterior_Sol_Oest',\n",
    " '16:Meteo_Exterior_Sol_Est',\n",
    " '20:Exterior_Entalpic_2',\n",
    " '21:Exterior_Entalpic_turbo',\n",
    " '22:Temperature_Exterior_Sensor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>1:Date</th>\n",
       "      <th>2:Time</th>\n",
       "      <th>3:Temperature_Comedor_Sensor</th>\n",
       "      <th>4:Temperature_Habitacion_Sensor</th>\n",
       "      <th>5:Weather_Temperature</th>\n",
       "      <th>6:CO2_Comedor_Sensor</th>\n",
       "      <th>7:CO2_Habitacion_Sensor</th>\n",
       "      <th>8:Humedad_Comedor_Sensor</th>\n",
       "      <th>...</th>\n",
       "      <th>15:Meteo_Exterior_Sol_Oest</th>\n",
       "      <th>16:Meteo_Exterior_Sol_Est</th>\n",
       "      <th>17:Meteo_Exterior_Sol_Sud</th>\n",
       "      <th>18:Meteo_Exterior_Piranometro</th>\n",
       "      <th>19:Exterior_Entalpic_1</th>\n",
       "      <th>20:Exterior_Entalpic_2</th>\n",
       "      <th>21:Exterior_Entalpic_turbo</th>\n",
       "      <th>22:Temperature_Exterior_Sensor</th>\n",
       "      <th>23:Humedad_Exterior_Sensor</th>\n",
       "      <th>24:Day_Of_Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13/03/2012</td>\n",
       "      <td>11:45</td>\n",
       "      <td>18.1875</td>\n",
       "      <td>17.8275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.560</td>\n",
       "      <td>221.920</td>\n",
       "      <td>39.9125</td>\n",
       "      <td>42.4150</td>\n",
       "      <td>81.6650</td>\n",
       "      <td>...</td>\n",
       "      <td>95436.8</td>\n",
       "      <td>758.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.1150</td>\n",
       "      <td>48.3750</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13/03/2012</td>\n",
       "      <td>12:00</td>\n",
       "      <td>18.4633</td>\n",
       "      <td>18.1207</td>\n",
       "      <td>6.8</td>\n",
       "      <td>219.947</td>\n",
       "      <td>220.363</td>\n",
       "      <td>39.9267</td>\n",
       "      <td>42.2453</td>\n",
       "      <td>81.7413</td>\n",
       "      <td>...</td>\n",
       "      <td>95436.8</td>\n",
       "      <td>762.069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.4147</td>\n",
       "      <td>47.8080</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13/03/2012</td>\n",
       "      <td>12:15</td>\n",
       "      <td>18.7673</td>\n",
       "      <td>18.4367</td>\n",
       "      <td>17.0</td>\n",
       "      <td>219.403</td>\n",
       "      <td>218.933</td>\n",
       "      <td>39.7720</td>\n",
       "      <td>42.2267</td>\n",
       "      <td>81.4240</td>\n",
       "      <td>...</td>\n",
       "      <td>95398.6</td>\n",
       "      <td>766.251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.8533</td>\n",
       "      <td>47.4320</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13/03/2012</td>\n",
       "      <td>12:30</td>\n",
       "      <td>19.0727</td>\n",
       "      <td>18.7513</td>\n",
       "      <td>18.0</td>\n",
       "      <td>218.613</td>\n",
       "      <td>217.045</td>\n",
       "      <td>39.7760</td>\n",
       "      <td>42.0987</td>\n",
       "      <td>81.5013</td>\n",
       "      <td>...</td>\n",
       "      <td>95360.3</td>\n",
       "      <td>766.037</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.2907</td>\n",
       "      <td>47.0240</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13/03/2012</td>\n",
       "      <td>12:45</td>\n",
       "      <td>19.3721</td>\n",
       "      <td>19.0414</td>\n",
       "      <td>20.0</td>\n",
       "      <td>217.714</td>\n",
       "      <td>216.080</td>\n",
       "      <td>39.7757</td>\n",
       "      <td>42.0686</td>\n",
       "      <td>81.4657</td>\n",
       "      <td>...</td>\n",
       "      <td>95354.9</td>\n",
       "      <td>762.743</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.7400</td>\n",
       "      <td>45.4743</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            # Unnamed: 1   1:Date   2:Time  3:Temperature_Comedor_Sensor  \\\n",
       "0  13/03/2012      11:45  18.1875  17.8275                           0.0   \n",
       "1  13/03/2012      12:00  18.4633  18.1207                           6.8   \n",
       "2  13/03/2012      12:15  18.7673  18.4367                          17.0   \n",
       "3  13/03/2012      12:30  19.0727  18.7513                          18.0   \n",
       "4  13/03/2012      12:45  19.3721  19.0414                          20.0   \n",
       "\n",
       "   4:Temperature_Habitacion_Sensor  5:Weather_Temperature  \\\n",
       "0                          216.560                221.920   \n",
       "1                          219.947                220.363   \n",
       "2                          219.403                218.933   \n",
       "3                          218.613                217.045   \n",
       "4                          217.714                216.080   \n",
       "\n",
       "   6:CO2_Comedor_Sensor  7:CO2_Habitacion_Sensor  8:Humedad_Comedor_Sensor  \\\n",
       "0               39.9125                  42.4150                   81.6650   \n",
       "1               39.9267                  42.2453                   81.7413   \n",
       "2               39.7720                  42.2267                   81.4240   \n",
       "3               39.7760                  42.0987                   81.5013   \n",
       "4               39.7757                  42.0686                   81.4657   \n",
       "\n",
       "   ...  15:Meteo_Exterior_Sol_Oest  16:Meteo_Exterior_Sol_Est  \\\n",
       "0  ...                     95436.8                    758.880   \n",
       "1  ...                     95436.8                    762.069   \n",
       "2  ...                     95398.6                    766.251   \n",
       "3  ...                     95360.3                    766.037   \n",
       "4  ...                     95354.9                    762.743   \n",
       "\n",
       "   17:Meteo_Exterior_Sol_Sud  18:Meteo_Exterior_Piranometro  \\\n",
       "0                          0                              0   \n",
       "1                          0                              0   \n",
       "2                          0                              0   \n",
       "3                          0                              0   \n",
       "4                          0                              0   \n",
       "\n",
       "   19:Exterior_Entalpic_1  20:Exterior_Entalpic_2  21:Exterior_Entalpic_turbo  \\\n",
       "0                       0                 18.1150                     48.3750   \n",
       "1                       0                 18.4147                     47.8080   \n",
       "2                       0                 18.8533                     47.4320   \n",
       "3                       0                 19.2907                     47.0240   \n",
       "4                       0                 19.7400                     45.4743   \n",
       "\n",
       "   22:Temperature_Exterior_Sensor  23:Humedad_Exterior_Sensor  24:Day_Of_Week  \n",
       "0                             2.0                         NaN             NaN  \n",
       "1                             2.0                         NaN             NaN  \n",
       "2                             2.0                         NaN             NaN  \n",
       "3                             2.0                         NaN             NaN  \n",
       "4                             2.0                         NaN             NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 3200\n",
    "val_size = 400\n",
    "depth = 10\n",
    "batch_size = 128\n",
    "prediction_horizon = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = np.zeros((len(data1), depth, len(cols)))\n",
    "y_train1 = np.zeros((len(data1), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(cols):\n",
    "    for j in range(depth):\n",
    "        X_train1[:, j, i] = data1[name].shift(depth - j - 1).fillna(method=\"bfill\")\n",
    "y_train1 = data1[target].shift(-prediction_horizon).fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train1[depth:-prediction_horizon]\n",
    "y_train1 = y_train1[depth:-prediction_horizon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.zeros((len(data2), depth, len(cols)))\n",
    "y2 = np.zeros((len(data2), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(cols):\n",
    "    for j in range(depth):\n",
    "        X2[:, j, i] = data2[name].shift(depth - j - 1).fillna(method=\"bfill\")\n",
    "y2 = data2[target].shift(-prediction_horizon).fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X2[:train_size - len(data1)]\n",
    "y_train2 = y2[:train_size - len(data1)]\n",
    "\n",
    "X_val = X2[train_size - len(data1):train_size - len(data1) + val_size]\n",
    "y_val = y2[train_size - len(data1):train_size - len(data1) + val_size]\n",
    "\n",
    "X_test = X2[train_size - len(data1) + val_size:]\n",
    "y_test = y2[train_size - len(data1) + val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train2[depth:]\n",
    "y_train2 = y_train2[depth:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate([X_train1, X_train2], axis=0)\n",
    "y_train = np.concatenate([y_train1, y_train2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3179, 10, 17), (3179,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_min, y_train_min = X_train.min(axis=0), y_train.min(axis=0)\n",
    "X_train_max, y_train_max = X_train.max(axis=0), y_train.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train_min)/(X_train_max - X_train_min + 1e-9)\n",
    "X_val = (X_val - X_train_min)/(X_train_max - X_train_min + 1e-9)\n",
    "X_test = (X_test - X_train_min)/(X_train_max - X_train_min + 1e-9)\n",
    "\n",
    "y_train = (y_train - y_train_min)/(y_train_max - y_train_min + 1e-9)\n",
    "y_val = (y_val - y_train_min)/(y_train_max - y_train_min + 1e-9)\n",
    "y_test = (y_test - y_train_min)/(y_train_max - y_train_min + 1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = torch.Tensor(X_train)\n",
    "X_val_t = torch.Tensor(X_val)\n",
    "X_test_t = torch.Tensor(X_test)\n",
    "y_train_t = torch.Tensor(y_train)\n",
    "y_val_t = torch.Tensor(y_val.values)\n",
    "y_test_t = torch.Tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(TensorDataset(X_val_t, y_val_t), shuffle=False, batch_size=batch_size)\n",
    "test_loader = DataLoader(TensorDataset(X_test_t, y_test_t), shuffle=False, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMVFullLSTM(X_train.shape[2], 1, 128).cuda()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_scheduler = torch.optim.lr_scheduler.StepLR(opt, 20, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/tmp/ipykernel_8766/3449938588.py\", line 32, in forward\n            o_t = torch.sigmoid(self.W_o(inp))\n            # eq 3\n            c_t = c_t*f_t + i_t*j_tilda_t.view(j_tilda_t.shape[0], -1)\n                                ~~~~~~~~~~~~~~ <--- HERE\n            # eq 4\n            h_tilda_t = (o_t*torch.tanh(c_t)).view(h_tilda_t.shape[0], self.input_dim, self.n_units)\nRuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8766/1093488936.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cds/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/tmp/ipykernel_8766/3449938588.py\", line 32, in forward\n            o_t = torch.sigmoid(self.W_o(inp))\n            # eq 3\n            c_t = c_t*f_t + i_t*j_tilda_t.view(j_tilda_t.shape[0], -1)\n                                ~~~~~~~~~~~~~~ <--- HERE\n            # eq 4\n            h_tilda_t = (o_t*torch.tanh(c_t)).view(h_tilda_t.shape[0], self.input_dim, self.n_units)\nRuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "loss = nn.MSELoss()\n",
    "patience = 35\n",
    "min_val_loss = 9999\n",
    "counter = 0\n",
    "for i in range(epochs):\n",
    "    mse_train = 0\n",
    "    iteration_start = time.monotonic()\n",
    "    for batch_x, batch_y in train_loader :\n",
    "        batch_x = batch_x.cuda()\n",
    "        batch_y = batch_y.cuda()\n",
    "        opt.zero_grad()\n",
    "        y_pred, alphas, betas = model(batch_x)\n",
    "        y_pred = y_pred.squeeze(1)\n",
    "        l = loss(y_pred, batch_y)\n",
    "        l.backward()\n",
    "        mse_train += l.item()*batch_x.shape[0]\n",
    "        opt.step()\n",
    "    epoch_scheduler.step()\n",
    "    with torch.no_grad():\n",
    "        mse_val = 0\n",
    "        preds = []\n",
    "        true = []\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x = batch_x.cuda()\n",
    "            batch_y = batch_y.cuda()\n",
    "            output, alphas, betas = model(batch_x)\n",
    "            output = output.squeeze(1)\n",
    "            preds.append(output.detach().cpu().numpy())\n",
    "            true.append(batch_y.detach().cpu().numpy())\n",
    "            mse_val += loss(output, batch_y).item()*batch_x.shape[0]\n",
    "    preds = np.concatenate(preds)\n",
    "    true = np.concatenate(true)\n",
    "    \n",
    "    if min_val_loss > mse_val**0.5:\n",
    "        min_val_loss = mse_val**0.5\n",
    "        print(\"Saving...\")\n",
    "        torch.save(model.state_dict(), \"imv_lstm_sml2010.pt\")\n",
    "        counter = 0\n",
    "    else: \n",
    "        counter += 1\n",
    "    \n",
    "    if counter == patience:\n",
    "        break\n",
    "    print(\"Iter: \", i, \"train: \", (mse_train/len(X_train_t))**0.5, \"val: \", (mse_val/len(X_val_t))**0.5)\n",
    "    iteration_end = time.monotonic()\n",
    "    print(\"Iter time: \", iteration_end - iteration_start)\n",
    "    if(i % 10 == 0):\n",
    "        preds = preds*(y_train_max - y_train_min) + y_train_min\n",
    "        true = true*(y_train_max - y_train_min) + y_train_min\n",
    "        mse = mean_squared_error(true, preds)\n",
    "        mae = mean_absolute_error(true, preds)\n",
    "        print(\"mse: \", mse, \"mae: \", mae)\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.plot(preds)\n",
    "        plt.plot(true)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"imv_lstm_sml2010.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mse_val = 0\n",
    "    preds = []\n",
    "    true = []\n",
    "    alphas = []\n",
    "    betas = []\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x = batch_x.cuda()\n",
    "        batch_y = batch_y.cuda()\n",
    "        output, a, b = model(batch_x)\n",
    "        output = output.squeeze(1)\n",
    "        preds.append(output.detach().cpu().numpy())\n",
    "        true.append(batch_y.detach().cpu().numpy())\n",
    "        alphas.append(a.detach().cpu().numpy())\n",
    "        betas.append(b.detach().cpu().numpy())\n",
    "        mse_val += loss(output, batch_y).item()*batch_x.shape[0]\n",
    "preds = np.concatenate(preds)\n",
    "true = np.concatenate(true)\n",
    "alphas = np.concatenate(alphas)\n",
    "betas = np.concatenate(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds*(y_train_max - y_train_min) + y_train_min\n",
    "true = true*(y_train_max - y_train_min) + y_train_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(true, preds)\n",
    "mae = mean_absolute_error(true, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(preds)\n",
    "plt.plot(true)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = alphas.mean(axis=0)\n",
    "betas = betas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = alphas[..., 0]\n",
    "betas = betas[..., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = alphas.transpose(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "im = ax.imshow(alphas)\n",
    "ax.set_xticks(np.arange(X_train_t.shape[1]))\n",
    "ax.set_yticks(np.arange(len(cols)))\n",
    "ax.set_xticklabels([\"t-\"+str(i) for i in np.arange(X_train_t.shape[1], -1, -1)])\n",
    "ax.set_yticklabels(cols)\n",
    "for i in range(len(cols)):\n",
    "    for j in range(X_train_t.shape[1]):\n",
    "        text = ax.text(j, i, round(alphas[i, j], 3),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "ax.set_title(\"Importance of features and timesteps\")\n",
    "#fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Feature importance\")\n",
    "plt.bar(range(len(cols)), betas)\n",
    "plt.xticks(range(len(cols)), cols, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
